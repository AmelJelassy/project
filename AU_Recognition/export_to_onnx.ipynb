{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from data import MyDataset\n",
    "from models.swin import SwinTransformer\n",
    "from models.resnet18 import ResNet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = 12\n",
    "aus = [1,2,4,5,6,9,12,15,17,20,25,26]\n",
    "batch_size = 512\n",
    "num_workers = 1\n",
    "train = False\n",
    "device = \"cpu\"\n",
    "data_root = \"../data\"\n",
    "data = \"DISFA\"\n",
    "onnx_name = \"FaceAU\"\n",
    "test_csv = os.path.join(data_root, data, \"labels_intensity_5\", \"all\", \"test.csv\")\n",
    "dropout = 0.1\n",
    "fm_distillation = False\n",
    "\n",
    "class SwinConfig:\n",
    "\tdef __init__(self):\n",
    "\t\tself.device = device\n",
    "\t\tself.dropout = 0.1\n",
    "\t\tself.num_labels = num_labels\n",
    "\n",
    "class AU2HeatmapConfig:\n",
    "\tdef __init__(self):\n",
    "\t\tself.data = data\n",
    "\t\tself.sigma = 10.0\n",
    "\t\tself.num_labels = num_labels\n",
    "\n",
    "class DatasetConfig(AU2HeatmapConfig):\n",
    "\tdef __init__(self):\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.data = data\n",
    "\t\tself.data_root = data_root\n",
    "\t\tself.image_size = 256\n",
    "\t\tself.crop_size = 224\n",
    "\n",
    "class ResNet18Config:\n",
    "\tdef __init__(self):\n",
    "\t\tself.fm_distillation = fm_distillation\n",
    "\t\tself.dropout = dropout\n",
    "\t\tself.num_labels = num_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_config = DatasetConfig()\n",
    "dataset = MyDataset(test_csv, train, dataset_config)\n",
    "loader = DataLoader(\n",
    "\tdataset=dataset,\n",
    "\tbatch_size=batch_size,\n",
    "\tnum_workers=num_workers,\n",
    "\tshuffle=train,\n",
    "\tcollate_fn=dataset.collate_fn,\n",
    "\tdrop_last=train\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\P\\anaconda3\\envs\\Alignment\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\P\\anaconda3\\envs\\Alignment\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Swin\n",
    "model_config = SwinConfig()\n",
    "model = SwinTransformer(model_config)\n",
    "ckpt_name = os.path.join(\"swin_checkpoint\", data, \"0\", \"swin.pt\")\n",
    "\"\"\"\n",
    "\n",
    "# ResNet18\n",
    "model_config = ResNet18Config()\n",
    "model = ResNet18(model_config)\n",
    "ckpt_name = os.path.join(\"resnet_disfa_all\", data, \"all\", \"resnet.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet18(\n",
       "  (encoder): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (7): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (8): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Dropout(p=0.1, inplace=False)\n",
       "    (4): Linear(in_features=128, out_features=12, bias=True)\n",
       "    (5): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoints = torch.load(ckpt_name, map_location=torch.device(device))[\"model\"]\n",
    "model.load_state_dict(checkpoints, strict=True)\n",
    "torch.no_grad()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ Diagnostic Run torch.onnx.export version 2.0.1 ================\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "for images, labels in loader:\n",
    "\timages = images.to(device)\n",
    "\tlabels = labels.to(device)\n",
    "\tlabels_pred = model(images)\n",
    "\tlabels_pred = torch.clamp(labels_pred, min=0.0, max=5.0)\n",
    "\"\"\"\n",
    "\n",
    "dummy_input = torch.rand((1, 3, 224, 224), device=device)\n",
    "input_names = [ \"image\" ]\n",
    "output_names = [ \"AUs\" ]\n",
    "onnx_name = onnx_name + datetime.now().strftime(\"%Y%m%d%H%M%S\") + \".onnx\"\n",
    "\n",
    "torch.onnx.export(\n",
    "\tmodel, \n",
    "\tdummy_input, \n",
    "\tonnx_name, \n",
    "\tverbose=True, \n",
    "\tinput_names=input_names,\n",
    "\toutput_names=output_names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph torch_jit (\n",
      "  %image[FLOAT, 1x3x224x224]\n",
      ") initializers (\n",
      "  %classifier.0.weight[FLOAT, 128x512]\n",
      "  %classifier.0.bias[FLOAT, 128]\n",
      "  %classifier.2.weight[FLOAT, 128]\n",
      "  %classifier.2.bias[FLOAT, 128]\n",
      "  %classifier.2.running_mean[FLOAT, 128]\n",
      "  %classifier.2.running_var[FLOAT, 128]\n",
      "  %classifier.4.weight[FLOAT, 12x128]\n",
      "  %classifier.4.bias[FLOAT, 12]\n",
      "  %onnx::Conv_211[FLOAT, 64x3x7x7]\n",
      "  %onnx::Conv_212[FLOAT, 64]\n",
      "  %onnx::Conv_214[FLOAT, 64x64x3x3]\n",
      "  %onnx::Conv_215[FLOAT, 64]\n",
      "  %onnx::Conv_217[FLOAT, 64x64x3x3]\n",
      "  %onnx::Conv_218[FLOAT, 64]\n",
      "  %onnx::Conv_220[FLOAT, 64x64x3x3]\n",
      "  %onnx::Conv_221[FLOAT, 64]\n",
      "  %onnx::Conv_223[FLOAT, 64x64x3x3]\n",
      "  %onnx::Conv_224[FLOAT, 64]\n",
      "  %onnx::Conv_226[FLOAT, 128x64x3x3]\n",
      "  %onnx::Conv_227[FLOAT, 128]\n",
      "  %onnx::Conv_229[FLOAT, 128x128x3x3]\n",
      "  %onnx::Conv_230[FLOAT, 128]\n",
      "  %onnx::Conv_232[FLOAT, 128x64x1x1]\n",
      "  %onnx::Conv_233[FLOAT, 128]\n",
      "  %onnx::Conv_235[FLOAT, 128x128x3x3]\n",
      "  %onnx::Conv_236[FLOAT, 128]\n",
      "  %onnx::Conv_238[FLOAT, 128x128x3x3]\n",
      "  %onnx::Conv_239[FLOAT, 128]\n",
      "  %onnx::Conv_241[FLOAT, 256x128x3x3]\n",
      "  %onnx::Conv_242[FLOAT, 256]\n",
      "  %onnx::Conv_244[FLOAT, 256x256x3x3]\n",
      "  %onnx::Conv_245[FLOAT, 256]\n",
      "  %onnx::Conv_247[FLOAT, 256x128x1x1]\n",
      "  %onnx::Conv_248[FLOAT, 256]\n",
      "  %onnx::Conv_250[FLOAT, 256x256x3x3]\n",
      "  %onnx::Conv_251[FLOAT, 256]\n",
      "  %onnx::Conv_253[FLOAT, 256x256x3x3]\n",
      "  %onnx::Conv_254[FLOAT, 256]\n",
      "  %onnx::Conv_256[FLOAT, 512x256x3x3]\n",
      "  %onnx::Conv_257[FLOAT, 512]\n",
      "  %onnx::Conv_259[FLOAT, 512x512x3x3]\n",
      "  %onnx::Conv_260[FLOAT, 512]\n",
      "  %onnx::Conv_262[FLOAT, 512x256x1x1]\n",
      "  %onnx::Conv_263[FLOAT, 512]\n",
      "  %onnx::Conv_265[FLOAT, 512x512x3x3]\n",
      "  %onnx::Conv_266[FLOAT, 512]\n",
      "  %onnx::Conv_268[FLOAT, 512x512x3x3]\n",
      "  %onnx::Conv_269[FLOAT, 512]\n",
      ") {\n",
      "  %/encoder/encoder.0/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [7, 7], pads = [3, 3, 3, 3], strides = [2, 2]](%image, %onnx::Conv_211, %onnx::Conv_212)\n",
      "  %/encoder/encoder.2/Relu_output_0 = Relu(%/encoder/encoder.0/Conv_output_0)\n",
      "  %/encoder/encoder.3/MaxPool_output_0 = MaxPool[ceil_mode = 0, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [2, 2]](%/encoder/encoder.2/Relu_output_0)\n",
      "  %/encoder/encoder.4/encoder.4.0/conv1/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/encoder/encoder.3/MaxPool_output_0, %onnx::Conv_214, %onnx::Conv_215)\n",
      "  %/encoder/encoder.4/encoder.4.0/relu/Relu_output_0 = Relu(%/encoder/encoder.4/encoder.4.0/conv1/Conv_output_0)\n",
      "  %/encoder/encoder.4/encoder.4.0/conv2/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/encoder/encoder.4/encoder.4.0/relu/Relu_output_0, %onnx::Conv_217, %onnx::Conv_218)\n",
      "  %/encoder/encoder.4/encoder.4.0/Add_output_0 = Add(%/encoder/encoder.4/encoder.4.0/conv2/Conv_output_0, %/encoder/encoder.3/MaxPool_output_0)\n",
      "  %/encoder/encoder.4/encoder.4.0/relu_1/Relu_output_0 = Relu(%/encoder/encoder.4/encoder.4.0/Add_output_0)\n",
      "  %/encoder/encoder.4/encoder.4.1/conv1/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/encoder/encoder.4/encoder.4.0/relu_1/Relu_output_0, %onnx::Conv_220, %onnx::Conv_221)\n",
      "  %/encoder/encoder.4/encoder.4.1/relu/Relu_output_0 = Relu(%/encoder/encoder.4/encoder.4.1/conv1/Conv_output_0)\n",
      "  %/encoder/encoder.4/encoder.4.1/conv2/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/encoder/encoder.4/encoder.4.1/relu/Relu_output_0, %onnx::Conv_223, %onnx::Conv_224)\n",
      "  %/encoder/encoder.4/encoder.4.1/Add_output_0 = Add(%/encoder/encoder.4/encoder.4.1/conv2/Conv_output_0, %/encoder/encoder.4/encoder.4.0/relu_1/Relu_output_0)\n",
      "  %/encoder/encoder.4/encoder.4.1/relu_1/Relu_output_0 = Relu(%/encoder/encoder.4/encoder.4.1/Add_output_0)\n",
      "  %/encoder/encoder.5/encoder.5.0/conv1/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [2, 2]](%/encoder/encoder.4/encoder.4.1/relu_1/Relu_output_0, %onnx::Conv_226, %onnx::Conv_227)\n",
      "  %/encoder/encoder.5/encoder.5.0/relu/Relu_output_0 = Relu(%/encoder/encoder.5/encoder.5.0/conv1/Conv_output_0)\n",
      "  %/encoder/encoder.5/encoder.5.0/conv2/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/encoder/encoder.5/encoder.5.0/relu/Relu_output_0, %onnx::Conv_229, %onnx::Conv_230)\n",
      "  %/encoder/encoder.5/encoder.5.0/downsample/downsample.0/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [2, 2]](%/encoder/encoder.4/encoder.4.1/relu_1/Relu_output_0, %onnx::Conv_232, %onnx::Conv_233)\n",
      "  %/encoder/encoder.5/encoder.5.0/Add_output_0 = Add(%/encoder/encoder.5/encoder.5.0/conv2/Conv_output_0, %/encoder/encoder.5/encoder.5.0/downsample/downsample.0/Conv_output_0)\n",
      "  %/encoder/encoder.5/encoder.5.0/relu_1/Relu_output_0 = Relu(%/encoder/encoder.5/encoder.5.0/Add_output_0)\n",
      "  %/encoder/encoder.5/encoder.5.1/conv1/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/encoder/encoder.5/encoder.5.0/relu_1/Relu_output_0, %onnx::Conv_235, %onnx::Conv_236)\n",
      "  %/encoder/encoder.5/encoder.5.1/relu/Relu_output_0 = Relu(%/encoder/encoder.5/encoder.5.1/conv1/Conv_output_0)\n",
      "  %/encoder/encoder.5/encoder.5.1/conv2/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/encoder/encoder.5/encoder.5.1/relu/Relu_output_0, %onnx::Conv_238, %onnx::Conv_239)\n",
      "  %/encoder/encoder.5/encoder.5.1/Add_output_0 = Add(%/encoder/encoder.5/encoder.5.1/conv2/Conv_output_0, %/encoder/encoder.5/encoder.5.0/relu_1/Relu_output_0)\n",
      "  %/encoder/encoder.5/encoder.5.1/relu_1/Relu_output_0 = Relu(%/encoder/encoder.5/encoder.5.1/Add_output_0)\n",
      "  %/encoder/encoder.6/encoder.6.0/conv1/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [2, 2]](%/encoder/encoder.5/encoder.5.1/relu_1/Relu_output_0, %onnx::Conv_241, %onnx::Conv_242)\n",
      "  %/encoder/encoder.6/encoder.6.0/relu/Relu_output_0 = Relu(%/encoder/encoder.6/encoder.6.0/conv1/Conv_output_0)\n",
      "  %/encoder/encoder.6/encoder.6.0/conv2/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/encoder/encoder.6/encoder.6.0/relu/Relu_output_0, %onnx::Conv_244, %onnx::Conv_245)\n",
      "  %/encoder/encoder.6/encoder.6.0/downsample/downsample.0/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [2, 2]](%/encoder/encoder.5/encoder.5.1/relu_1/Relu_output_0, %onnx::Conv_247, %onnx::Conv_248)\n",
      "  %/encoder/encoder.6/encoder.6.0/Add_output_0 = Add(%/encoder/encoder.6/encoder.6.0/conv2/Conv_output_0, %/encoder/encoder.6/encoder.6.0/downsample/downsample.0/Conv_output_0)\n",
      "  %/encoder/encoder.6/encoder.6.0/relu_1/Relu_output_0 = Relu(%/encoder/encoder.6/encoder.6.0/Add_output_0)\n",
      "  %/encoder/encoder.6/encoder.6.1/conv1/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/encoder/encoder.6/encoder.6.0/relu_1/Relu_output_0, %onnx::Conv_250, %onnx::Conv_251)\n",
      "  %/encoder/encoder.6/encoder.6.1/relu/Relu_output_0 = Relu(%/encoder/encoder.6/encoder.6.1/conv1/Conv_output_0)\n",
      "  %/encoder/encoder.6/encoder.6.1/conv2/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/encoder/encoder.6/encoder.6.1/relu/Relu_output_0, %onnx::Conv_253, %onnx::Conv_254)\n",
      "  %/encoder/encoder.6/encoder.6.1/Add_output_0 = Add(%/encoder/encoder.6/encoder.6.1/conv2/Conv_output_0, %/encoder/encoder.6/encoder.6.0/relu_1/Relu_output_0)\n",
      "  %/encoder/encoder.6/encoder.6.1/relu_1/Relu_output_0 = Relu(%/encoder/encoder.6/encoder.6.1/Add_output_0)\n",
      "  %/encoder/encoder.7/encoder.7.0/conv1/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [2, 2]](%/encoder/encoder.6/encoder.6.1/relu_1/Relu_output_0, %onnx::Conv_256, %onnx::Conv_257)\n",
      "  %/encoder/encoder.7/encoder.7.0/relu/Relu_output_0 = Relu(%/encoder/encoder.7/encoder.7.0/conv1/Conv_output_0)\n",
      "  %/encoder/encoder.7/encoder.7.0/conv2/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/encoder/encoder.7/encoder.7.0/relu/Relu_output_0, %onnx::Conv_259, %onnx::Conv_260)\n",
      "  %/encoder/encoder.7/encoder.7.0/downsample/downsample.0/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [2, 2]](%/encoder/encoder.6/encoder.6.1/relu_1/Relu_output_0, %onnx::Conv_262, %onnx::Conv_263)\n",
      "  %/encoder/encoder.7/encoder.7.0/Add_output_0 = Add(%/encoder/encoder.7/encoder.7.0/conv2/Conv_output_0, %/encoder/encoder.7/encoder.7.0/downsample/downsample.0/Conv_output_0)\n",
      "  %/encoder/encoder.7/encoder.7.0/relu_1/Relu_output_0 = Relu(%/encoder/encoder.7/encoder.7.0/Add_output_0)\n",
      "  %/encoder/encoder.7/encoder.7.1/conv1/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/encoder/encoder.7/encoder.7.0/relu_1/Relu_output_0, %onnx::Conv_265, %onnx::Conv_266)\n",
      "  %/encoder/encoder.7/encoder.7.1/relu/Relu_output_0 = Relu(%/encoder/encoder.7/encoder.7.1/conv1/Conv_output_0)\n",
      "  %/encoder/encoder.7/encoder.7.1/conv2/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/encoder/encoder.7/encoder.7.1/relu/Relu_output_0, %onnx::Conv_268, %onnx::Conv_269)\n",
      "  %/encoder/encoder.7/encoder.7.1/Add_output_0 = Add(%/encoder/encoder.7/encoder.7.1/conv2/Conv_output_0, %/encoder/encoder.7/encoder.7.0/relu_1/Relu_output_0)\n",
      "  %/encoder/encoder.7/encoder.7.1/relu_1/Relu_output_0 = Relu(%/encoder/encoder.7/encoder.7.1/Add_output_0)\n",
      "  %/encoder/encoder.8/GlobalAveragePool_output_0 = GlobalAveragePool(%/encoder/encoder.7/encoder.7.1/relu_1/Relu_output_0)\n",
      "  %/Constant_output_0 = Constant[value = <Tensor>]()\n",
      "  %/Reshape_output_0 = Reshape[allowzero = 0](%/encoder/encoder.8/GlobalAveragePool_output_0, %/Constant_output_0)\n",
      "  %/classifier/classifier.0/Gemm_output_0 = Gemm[alpha = 1, beta = 1, transB = 1](%/Reshape_output_0, %classifier.0.weight, %classifier.0.bias)\n",
      "  %/classifier/classifier.1/Relu_output_0 = Relu(%/classifier/classifier.0/Gemm_output_0)\n",
      "  %/classifier/classifier.2/BatchNormalization_output_0 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142, training_mode = 0](%/classifier/classifier.1/Relu_output_0, %classifier.2.weight, %classifier.2.bias, %classifier.2.running_mean, %classifier.2.running_var)\n",
      "  %/classifier/classifier.4/Gemm_output_0 = Gemm[alpha = 1, beta = 1, transB = 1](%/classifier/classifier.2/BatchNormalization_output_0, %classifier.4.weight, %classifier.4.bias)\n",
      "  %AUs = Sigmoid(%/classifier/classifier.4/Gemm_output_0)\n",
      "  return %AUs\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "model = onnx.load(onnx_name)\n",
    "onnx.checker.check_model(model)\n",
    "print(onnx.helper.printable_graph(model.graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime as ort\n",
    "import numpy as np\n",
    "\n",
    "ort_session = ort.InferenceSession(onnx_name)\n",
    "\n",
    "image, label = next(iter(dataset))\n",
    "image = image.unsqueeze(dim=0)\n",
    "image = image.numpy()\n",
    "\n",
    "label_pred = ort_session.run(\n",
    "    None,\n",
    "    {\"image\": image},\n",
    ")[0]\n",
    "label_pred = np.squeeze(label_pred, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AU1:\tdiff=0.0046\tpred=0.0046\tgt=0.0000\n",
      "AU2:\tdiff=0.0028\tpred=0.0028\tgt=0.0000\n",
      "AU4:\tdiff=0.0008\tpred=0.0008\tgt=0.0000\n",
      "AU5:\tdiff=0.0007\tpred=0.0007\tgt=0.0000\n",
      "AU6:\tdiff=0.0154\tpred=0.0154\tgt=0.0000\n",
      "AU9:\tdiff=0.0015\tpred=0.0015\tgt=0.0000\n",
      "AU12:\tdiff=1.6542\tpred=0.3458\tgt=2.0000\n",
      "AU15:\tdiff=0.0011\tpred=0.0011\tgt=0.0000\n",
      "AU17:\tdiff=0.0018\tpred=0.0018\tgt=0.0000\n",
      "AU20:\tdiff=0.0070\tpred=0.0070\tgt=0.0000\n",
      "AU25:\tdiff=0.0149\tpred=0.0149\tgt=0.0000\n",
      "AU26:\tdiff=0.0100\tpred=0.0100\tgt=0.0000\n"
     ]
    }
   ],
   "source": [
    "for i in range(num_labels):\n",
    "    gt = label[i]\n",
    "    pred = label_pred[i]\n",
    "    print(f\"AU{aus[i]}:\\tdiff={abs(pred - gt):.4f}\\tpred={pred:.4f}\\tgt={gt:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4f76a724a0076d5c39752e12bec55adbbf3b081a4d622e794e00deba6a6ff878"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
